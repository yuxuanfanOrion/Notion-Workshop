<!-- notion-id: 2d12a5ae-4040-803c-8475-fc5bff17f01f -->
Title: CBench: Evaluating Cinematic Reasoning and Directorial Intent in Multi-modal LLMs



- Introduction
  - 

  - Contribution
    - We introduce **Cinematic Reasoning**, a novel video understanding task that moves beyond traditional literal description and action recognition. Unlike existing benchmarks that focus on *intra-shot* perception (e.g., "what is the man doing?"), our task requires **inter-shot inferential reasoning** grounded in formal film theory (e.g., Montage, Kuleshov Effect). This is the first work to systematically evaluate Video-LLMs' ability to decode **directorial intent** and **implicit narrative structures**.

    - We present [xxxx] Benchmark 

    - We benchmark state-of-the-art vision-language models

    - [TBD] We present [xxxxx] Dataset with detailed cinematic caption

- Related work
  - Large Video Language Models

  - Video Understanding Benchmarks

- Cinematic Reasoning Benchmark
  - 

- Experiments
  - setting

  - results
    - **main** (fixed uniform sampling - 32 frames)
      - proprietary models: GPT-5, Gemini-3, …

      - Open-source VLMs: Qwen3-VL, 

      - Open-source LVLMs: Video-LLaMA3, ..

    - **frames numbers (4, 8, 16, 32, 64, …)**

    - Audio 

    - 

- Conclusion
